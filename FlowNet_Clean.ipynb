{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!apt install tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!tree /kaggle/input/flownet-model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Flow with FlowNet on KITTI Dataset\n",
    "\n",
    "Clean, organized notebook for computing optical flow using pretrained FlowNet models.\n",
    "\n",
    "**Dataset**: KITTI 2011_09_28_drive_0038_sync (110 frames)  \n",
    "**Model**: FlowNetS (pretrained)  \n",
    "**Task**: Compute optical flow between consecutive frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:39:59.284623Z",
     "iopub.status.busy": "2025-11-11T19:39:59.283883Z",
     "iopub.status.idle": "2025-11-11T19:40:03.716122Z",
     "shell.execute_reply": "2025-11-11T19:40:03.715312Z",
     "shell.execute_reply.started": "2025-11-11T19:39:59.284601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Download FlowNetPytorch Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:40:49.006248Z",
     "iopub.status.busy": "2025-11-11T19:40:49.005686Z",
     "iopub.status.idle": "2025-11-11T19:40:49.932944Z",
     "shell.execute_reply": "2025-11-11T19:40:49.932172Z",
     "shell.execute_reply.started": "2025-11-11T19:40:49.006213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Clone FlowNetPytorch repository if it doesn't exist\n",
    "flownet_path = '/kaggle/working/FlowNetPytorch'\n",
    "\n",
    "if not os.path.exists(flownet_path):\n",
    "    print(\"Cloning FlowNetPytorch repository...\")\n",
    "    # Change to working directory first\n",
    "    !cd /kaggle/working && git clone https://github.com/ClementPinard/FlowNetPytorch.git\n",
    "    \n",
    "    if os.path.exists(flownet_path):\n",
    "        print(\"✓ Repository cloned successfully\")\n",
    "    else:\n",
    "        print(\"⚠ Clone may have failed, but continuing...\")\n",
    "else:\n",
    "    print(\"FlowNetPytorch already exists\")\n",
    "\n",
    "# Add to Python path\n",
    "if flownet_path not in sys.path:\n",
    "    sys.path.insert(0, flownet_path)\n",
    "    \n",
    "print(f\"✓ Added FlowNetPytorch to path: {flownet_path}\")\n",
    "\n",
    "# Verify the repository structure\n",
    "if os.path.exists(flownet_path):\n",
    "    print(\"\\nRepository contents:\")\n",
    "    !ls -la /kaggle/working/FlowNetPytorch | head -15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-11T19:41:45.101226Z",
     "iopub.status.busy": "2025-11-11T19:41:45.100498Z",
     "iopub.status.idle": "2025-11-11T19:41:45.215424Z",
     "shell.execute_reply": "2025-11-11T19:41:45.214752Z",
     "shell.execute_reply.started": "2025-11-11T19:41:45.101192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"=\" * 60)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"✗ Using CPU\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load KITTI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:42:06.334577Z",
     "iopub.status.busy": "2025-11-11T19:42:06.333950Z",
     "iopub.status.idle": "2025-11-11T19:42:06.416818Z",
     "shell.execute_reply": "2025-11-11T19:42:06.416185Z",
     "shell.execute_reply.started": "2025-11-11T19:42:06.334551Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "base_dir = Path('/kaggle/input/flownet/2011_09_28/2011_09_28_drive_0038_sync')\n",
    "\n",
    "# Load image paths\n",
    "image_paths = sorted(glob.glob(str(base_dir / 'image_02' / 'data' / '*.png')))\n",
    "\n",
    "# Load timestamps\n",
    "with open(base_dir / 'image_02' / 'timestamps.txt', 'r') as f:\n",
    "    timestamps = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'frame_id': range(len(image_paths)),\n",
    "    'timestamp': pd.to_datetime(timestamps),\n",
    "    'image_path': image_paths\n",
    "})\n",
    "\n",
    "print(f\"✓ Loaded {len(df)} frames\")\n",
    "print(f\"  Duration: {df['timestamp'].iloc[-1] - df['timestamp'].iloc[0]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:42:35.024447Z",
     "iopub.status.busy": "2025-11-11T19:42:35.023812Z",
     "iopub.status.idle": "2025-11-11T19:42:36.035204Z",
     "shell.execute_reply": "2025-11-11T19:42:36.034388Z",
     "shell.execute_reply.started": "2025-11-11T19:42:35.024425Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_sample_and_velocity(df, idx):\n",
    "    \"\"\"\n",
    "    Visualizes a sample image and its associated 'velocity'.\n",
    "    Args:\n",
    "        df: DataFrame with ['frame_id', 'timestamp', 'image_path']\n",
    "        idx: Index (int) of sample to show\n",
    "    \"\"\"\n",
    "    img_path = df.iloc[idx]['image_path']\n",
    "    img = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Compute 'velocity' based on time difference between consecutive frames\n",
    "    if 0 < idx < len(df)-1:\n",
    "        t_prev = df.iloc[idx-1]['timestamp']\n",
    "        t_next = df.iloc[idx+1]['timestamp']\n",
    "        dt = (t_next - t_prev).total_seconds() / 2\n",
    "    elif idx == 0 and len(df) > 1:\n",
    "        dt = (df.iloc[1]['timestamp'] - df.iloc[0]['timestamp']).total_seconds()\n",
    "    else:\n",
    "        dt = None\n",
    "\n",
    "    # Show image\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Frame {df.iloc[idx]['frame_id']}  |  Timestamp: {df.iloc[idx]['timestamp']}\\n\"\n",
    "              + (f\"Δt ~ {dt:.4f} sec\" if dt is not None else \"No Δt\"))\n",
    "    plt.show()\n",
    "\n",
    "# Example: Visualize a few samples and 'velocities'\n",
    "for i in [0, 10, 50, 100]:\n",
    "    if i < len(df):\n",
    "        show_sample_and_velocity(df, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load FlowNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:42:59.391250Z",
     "iopub.status.busy": "2025-11-11T19:42:59.390914Z",
     "iopub.status.idle": "2025-11-11T19:42:59.533686Z",
     "shell.execute_reply": "2025-11-11T19:42:59.532917Z",
     "shell.execute_reply.started": "2025-11-11T19:42:59.391224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!tree /kaggle/input/flownet-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:43:20.164917Z",
     "iopub.status.busy": "2025-11-11T19:43:20.164328Z",
     "iopub.status.idle": "2025-11-11T19:43:22.551038Z",
     "shell.execute_reply": "2025-11-11T19:43:22.550342Z",
     "shell.execute_reply.started": "2025-11-11T19:43:20.164887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Setup path and imports\n",
    "import os\n",
    "import sys\n",
    "import importlib.util\n",
    "\n",
    "flownet_path = '/kaggle/working/FlowNetPytorch'\n",
    "\n",
    "# Debug: Check current state\n",
    "print(f\"FlowNet path exists: {os.path.exists(flownet_path)}\")\n",
    "print(f\"models dir exists: {os.path.exists(os.path.join(flownet_path, 'models'))}\")\n",
    "print(f\"util.py exists: {os.path.exists(os.path.join(flownet_path, 'util.py'))}\")\n",
    "\n",
    "# Force add to beginning of sys.path\n",
    "if flownet_path in sys.path:\n",
    "    sys.path.remove(flownet_path)\n",
    "sys.path.insert(0, flownet_path)\n",
    "print(f\"✓ Path added. First 3 sys.path entries: {sys.path[:3]}\")\n",
    "\n",
    "# Clear any cached imports\n",
    "for mod in ['models', 'util', 'models.FlowNetS', 'models.FlowNetC']:\n",
    "    if mod in sys.modules:\n",
    "        del sys.modules[mod]\n",
    "\n",
    "# Try importing with better error handling\n",
    "try:\n",
    "    import models\n",
    "    print(f\"✓ models imported from: {models.__file__}\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"❌ Failed to import models: {e}\")\n",
    "    print(\"\\nTrying manual import...\")\n",
    "    # Manual workaround: load the module directly\n",
    "    spec = importlib.util.spec_from_file_location(\"models\", os.path.join(flownet_path, \"models\", \"__init__.py\"))\n",
    "    models = importlib.util.module_from_spec(spec)\n",
    "    sys.modules['models'] = models\n",
    "    spec.loader.exec_module(models)\n",
    "    print(f\"✓ models loaded manually\")\n",
    "\n",
    "try:\n",
    "    from util import flow2rgb\n",
    "    print(f\"✓ util imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"Failed to import util: {e}\")\n",
    "    print(\"\\nTrying manual import...\")\n",
    "    spec = importlib.util.spec_from_file_location(\"util\", os.path.join(flownet_path, \"util.py\"))\n",
    "    util = importlib.util.module_from_spec(spec)\n",
    "    sys.modules['util'] = util\n",
    "    spec.loader.exec_module(util)\n",
    "    flow2rgb = util.flow2rgb\n",
    "    print(f\"✓ util loaded manually\")\n",
    "\n",
    "print(\"\\n✓ All imports successful\")\n",
    "\n",
    "# Load checkpoint\n",
    "model_path = '/kaggle/input/flownet-model/pytorch/default/1/FlowNet Models/pytorch/flownets_EPE1.951.pth'\n",
    "network_data = torch.load(model_path, map_location=device)\n",
    "\n",
    "print(\"\\nLoading FlowNetS...\")\n",
    "print(f\"Architecture: {network_data.get('arch', 'flownets')}\")\n",
    "print(f\"Epoch: {network_data.get('epoch', 'N/A')}, EPE: {network_data.get('best_EPE', 'N/A'):.4f}\")\n",
    "\n",
    "# Get div_flow for scaling\n",
    "div_flow = network_data.get('div_flow', 20.0)\n",
    "print(f\"div_flow: {div_flow}\")\n",
    "\n",
    "# Create model using the proper factory function\n",
    "model = models.flownets(network_data).to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"\\n✓ Model loaded successfully\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:44:20.963421Z",
     "iopub.status.busy": "2025-11-11T19:44:20.962772Z",
     "iopub.status.idle": "2025-11-11T19:44:20.972333Z",
     "shell.execute_reply": "2025-11-11T19:44:20.971605Z",
     "shell.execute_reply.started": "2025-11-11T19:44:20.963387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_flow(model, img1, img2, device, div_flow=20.0):\n",
    "    \"\"\"Compute optical flow using FlowNetPytorch (ClementPinard implementation).\"\"\"\n",
    "    with torch.no_grad():\n",
    "        h, w = img1.shape[:2]\n",
    "        \n",
    "        # Pad to multiple of 64\n",
    "        h_pad = ((h - 1) // 64 + 1) * 64\n",
    "        w_pad = ((w - 1) // 64 + 1) * 64\n",
    "        \n",
    "        # Resize\n",
    "        img1_r = cv2.resize(img1, (w_pad, h_pad))\n",
    "        img2_r = cv2.resize(img2, (w_pad, h_pad))\n",
    "        \n",
    "        # Preprocess: BGR to RGB\n",
    "        img1_rgb = cv2.cvtColor(img1_r, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        img2_rgb = cv2.cvtColor(img2_r, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        \n",
    "        # Normalize (following FlowNetPytorch preprocessing)\n",
    "        # 1. Divide by 255 to get [0, 1]\n",
    "        # 2. Subtract RGB mean [0.411, 0.432, 0.45]\n",
    "        mean = np.array([0.411, 0.432, 0.45], dtype=np.float32)\n",
    "        img1_norm = (img1_rgb / 255.0) - mean\n",
    "        img2_norm = (img2_rgb / 255.0) - mean\n",
    "        \n",
    "        # Stack to [6, H, W]\n",
    "        img1_tensor = torch.from_numpy(img1_norm.transpose(2, 0, 1))\n",
    "        img2_tensor = torch.from_numpy(img2_norm.transpose(2, 0, 1))\n",
    "        input_tensor = torch.cat([img1_tensor, img2_tensor], 0).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Compute flow\n",
    "        output = model(input_tensor)\n",
    "        \n",
    "        # Get flow (output is downsampled by 4x)\n",
    "        flow = output.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "        \n",
    "        # Multiply by div_flow to get actual pixel displacement\n",
    "        flow = flow * div_flow\n",
    "        \n",
    "        # Upsample to original resolution\n",
    "        flow = cv2.resize(flow, (w, h))\n",
    "        \n",
    "        # Scale flow vectors proportionally\n",
    "        flow[:, :, 0] *= w / (w_pad / 4)\n",
    "        flow[:, :, 1] *= h / (h_pad / 4)\n",
    "    \n",
    "    return flow\n",
    "\n",
    "\n",
    "def visualize_flow(flow, max_value=None):\n",
    "    \"\"\"\n",
    "    Convert flow to RGB visualization using the proper flow2rgb from FlowNetPytorch.\n",
    "    This matches the visualization used in the GT images.\n",
    "    \n",
    "    Args:\n",
    "        flow: [H, W, 2] numpy array\n",
    "        max_value: optional max flow value for normalization\n",
    "    \n",
    "    Returns:\n",
    "        RGB image [H, W, 3] as uint8\n",
    "    \"\"\"\n",
    "    # Convert from [H, W, 2] to [2, H, W] tensor for flow2rgb\n",
    "    flow_tensor = torch.from_numpy(flow.transpose(2, 0, 1))\n",
    "    \n",
    "    # Use the proper flow2rgb function from FlowNetPytorch\n",
    "    rgb = flow2rgb(flow_tensor, max_value=max_value)\n",
    "    \n",
    "    # Convert from [3, H, W] to [H, W, 3] and scale to 0-255\n",
    "    rgb_image = (rgb.transpose(1, 2, 0) * 255).astype(np.uint8)\n",
    "    \n",
    "    return rgb_image\n",
    "\n",
    "print(\"✓ Functions ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:44:30.854436Z",
     "iopub.status.busy": "2025-11-11T19:44:30.854084Z",
     "iopub.status.idle": "2025-11-11T19:44:30.924827Z",
     "shell.execute_reply": "2025-11-11T19:44:30.924117Z",
     "shell.execute_reply.started": "2025-11-11T19:44:30.854414Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Quick test to verify preprocessing\n",
    "img1_test = cv2.imread(df.loc[0, 'image_path'])\n",
    "img1_rgb = cv2.cvtColor(img1_test, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "\n",
    "# Apply normalization\n",
    "mean = np.array([0.411, 0.432, 0.45], dtype=np.float32) * 255\n",
    "img1_norm = (img1_rgb - mean) / 255.0\n",
    "\n",
    "print(f\"Original range: [{img1_rgb.min():.1f}, {img1_rgb.max():.1f}]\")\n",
    "print(f\"Mean values: {mean}\")\n",
    "print(f\"After normalization: [{img1_norm.min():.3f}, {img1_norm.max():.3f}]\")\n",
    "print(f\"✓ Ready for inference\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:44:43.586132Z",
     "iopub.status.busy": "2025-11-11T19:44:43.585807Z",
     "iopub.status.idle": "2025-11-11T19:44:44.387089Z",
     "shell.execute_reply": "2025-11-11T19:44:44.386135Z",
     "shell.execute_reply.started": "2025-11-11T19:44:43.586111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load first two frames\n",
    "img1 = cv2.imread(df.loc[0, 'image_path'])\n",
    "img2 = cv2.imread(df.loc[1, 'image_path'])\n",
    "\n",
    "print(f\"Image shape: {img1.shape}\")\n",
    "\n",
    "# Compute flow (using div_flow from checkpoint)\n",
    "start = time.time()\n",
    "flow = compute_flow(model, img1, img2, device, div_flow=div_flow)\n",
    "print(f\"✓ Flow computed in {time.time() - start:.3f}s\")\n",
    "\n",
    "# Stats\n",
    "mag = np.sqrt(flow[:, :, 0]**2 + flow[:, :, 1]**2)\n",
    "print(f\"  Mean magnitude: {mag.mean():.2f} px\")\n",
    "print(f\"  Max magnitude: {mag.max():.2f} px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:45:10.368948Z",
     "iopub.status.busy": "2025-11-11T19:45:10.368309Z",
     "iopub.status.idle": "2025-11-11T19:45:11.063054Z",
     "shell.execute_reply": "2025-11-11T19:45:11.062107Z",
     "shell.execute_reply.started": "2025-11-11T19:45:10.368920Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Original frames\n",
    "axes[0, 0].imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Frame 0', fontsize=14)\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title('Frame 1', fontsize=14)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Flow visualization using proper flow2rgb\n",
    "flow_rgb = visualize_flow(flow, max_value=None)\n",
    "axes[1, 0].imshow(flow_rgb)\n",
    "axes[1, 0].set_title('Optical Flow (color-coded)', fontsize=14)\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "im = axes[1, 1].imshow(mag, cmap='jet')\n",
    "axes[1, 1].set_title('Flow Magnitude', fontsize=14)\n",
    "axes[1, 1].axis('off')\n",
    "plt.colorbar(im, ax=axes[1, 1], fraction=0.046)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Batch Process Multiple Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:45:39.565140Z",
     "iopub.status.busy": "2025-11-11T19:45:39.564832Z",
     "iopub.status.idle": "2025-11-11T19:45:41.811583Z",
     "shell.execute_reply": "2025-11-11T19:45:41.810796Z",
     "shell.execute_reply.started": "2025-11-11T19:45:39.565118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Process first 20 frame pairs\n",
    "n_frames = 20\n",
    "flows = []\n",
    "stats = []\n",
    "\n",
    "print(f\"Processing {n_frames} frame pairs...\")\n",
    "for i in tqdm(range(n_frames)):\n",
    "    img1 = cv2.imread(df.loc[i, 'image_path'])\n",
    "    img2 = cv2.imread(df.loc[i + 1, 'image_path'])\n",
    "    \n",
    "    flow = compute_flow(model, img1, img2, device, div_flow=div_flow)\n",
    "    flows.append(flow)\n",
    "    \n",
    "    mag = np.sqrt(flow[:, :, 0]**2 + flow[:, :, 1]**2)\n",
    "    stats.append({'mean': mag.mean(), 'max': mag.max()})\n",
    "\n",
    "stats_df = pd.DataFrame(stats)\n",
    "print(f\"\\n✓ Computed {len(flows)} flows\")\n",
    "print(f\"\\nStatistics:\")\n",
    "print(stats_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:45:59.676856Z",
     "iopub.status.busy": "2025-11-11T19:45:59.676252Z",
     "iopub.status.idle": "2025-11-11T19:46:02.203220Z",
     "shell.execute_reply": "2025-11-11T19:46:02.202456Z",
     "shell.execute_reply.started": "2025-11-11T19:45:59.676827Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot statistics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].plot(stats_df['mean'], 'b-o', linewidth=2)\n",
    "axes[0].set_title('Mean Flow Magnitude', fontsize=13)\n",
    "axes[0].set_xlabel('Frame Pair')\n",
    "axes[0].set_ylabel('Pixels')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(stats_df['max'], 'r-s', linewidth=2)\n",
    "axes[1].set_title('Max Flow Magnitude', fontsize=13)\n",
    "axes[1].set_xlabel('Frame Pair')\n",
    "axes[1].set_ylabel('Pixels')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show flow grid using proper flow2rgb\n",
    "fig, axes = plt.subplots(4, 5, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(min(20, len(flows))):\n",
    "    flow_rgb = visualize_flow(flows[i], max_value=None)\n",
    "    axes[i].imshow(flow_rgb)\n",
    "    axes[i].set_title(f'{i}→{i+1}', fontsize=10)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Optical Flow Sequence - KITTI Dataset', fontsize=16, y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:46:39.846475Z",
     "iopub.status.busy": "2025-11-11T19:46:39.845743Z",
     "iopub.status.idle": "2025-11-11T19:46:39.862538Z",
     "shell.execute_reply": "2025-11-11T19:46:39.861759Z",
     "shell.execute_reply.started": "2025-11-11T19:46:39.846447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save flow in standard .flo format\n",
    "output_dir = Path('/kaggle/working/flow_results')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save first flow\n",
    "def save_flo(flow, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(b'PIEH')\n",
    "        np.array([flow.shape[1], flow.shape[0]], dtype=np.int32).tofile(f)\n",
    "        flow.astype(np.float32).tofile(f)\n",
    "\n",
    "save_flo(flows[0], output_dir / 'flow_000.flo')\n",
    "stats_df.to_csv(output_dir / 'statistics.csv', index=False)\n",
    "\n",
    "print(f\"✓ Saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Flow with Arrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:47:18.998091Z",
     "iopub.status.busy": "2025-11-11T19:47:18.997767Z",
     "iopub.status.idle": "2025-11-11T19:47:19.828630Z",
     "shell.execute_reply": "2025-11-11T19:47:19.827663Z",
     "shell.execute_reply.started": "2025-11-11T19:47:18.998070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_flow_arrows(img, flow, step=16, scale=1.0, arrow_color='yellow'):\n",
    "    \"\"\"\n",
    "    Visualize optical flow as arrows overlaid on the image.\n",
    "    \n",
    "    Args:\n",
    "        img: Background image (BGR format from cv2)\n",
    "        flow: Flow field [H, W, 2]\n",
    "        step: Arrow spacing (sample every N pixels)\n",
    "        scale: Arrow length scale factor\n",
    "        arrow_color: Color of arrows ('yellow', 'red', 'white', etc.)\n",
    "    \"\"\"\n",
    "    h, w = flow.shape[:2]\n",
    "    \n",
    "    # Create meshgrid for arrow positions\n",
    "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
    "    \n",
    "    # Get flow vectors at sampled positions\n",
    "    fx, fy = flow[y, x].T\n",
    "    \n",
    "    # Convert image to RGB for display\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    ax.imshow(img_rgb)\n",
    "    \n",
    "    # Plot arrows (quiver plot)\n",
    "    ax.quiver(x, y, fx, fy, \n",
    "              angles='xy', scale_units='xy', scale=1/scale,\n",
    "              color=arrow_color, width=0.0015, headwidth=4, headlength=5)\n",
    "    \n",
    "    ax.set_title('Optical Flow - Arrow Visualization', fontsize=14)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize first frame with flow arrows\n",
    "print(\"Visualizing optical flow with arrows...\")\n",
    "visualize_flow_arrows(img1, flow, step=20, scale=2.0, arrow_color='lime')\n",
    "\n",
    "# Alternative: Show arrows on darker background for better visibility\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Left: Original with arrows\n",
    "h, w = flow.shape[:2]\n",
    "y, x = np.mgrid[10:h:20, 10:w:20].reshape(2, -1).astype(int)\n",
    "fx, fy = flow[y, x].T\n",
    "img_rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "axes[0].imshow(img_rgb)\n",
    "axes[0].quiver(x, y, fx, fy, angles='xy', scale_units='xy', scale=0.5,\n",
    "               color='yellow', width=0.0015, headwidth=4, headlength=5)\n",
    "axes[0].set_title('Flow Arrows on Original Image', fontsize=13)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Right: Arrows on black background (clearer visualization)\n",
    "axes[1].set_facecolor('black')\n",
    "axes[1].quiver(x, y, fx, fy, angles='xy', scale_units='xy', scale=0.5,\n",
    "               color='cyan', width=0.0015, headwidth=4, headlength=5)\n",
    "axes[1].set_xlim(0, w)\n",
    "axes[1].set_ylim(h, 0)  # Invert y-axis to match image coordinates\n",
    "axes[1].set_title('Flow Arrows (Black Background)', fontsize=13)\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Arrow visualization complete\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8706159,
     "sourceId": 13688818,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 498070,
     "modelInstanceId": 482464,
     "sourceId": 639684,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
